{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PLAYER_HEADERS = ['id', 'age', 'ast', 'blk', 'drb', 'efg_pct', 'fg', 'fg2', 'fg2_pct',\n",
    "       'fg2a', 'fg3', 'fg3_pct', 'fg3a', 'fg_pct', 'fga', 'first_name',\n",
    "       'ft', 'ft_pct', 'fta', 'g', 'gs', 'last_name', 'mp', 'orb', 'pf',\n",
    "       'pos', 'pts', 'stl', 'teams', 'tov', 'trb', 'season']\n",
    "\n",
    "DUNK_HEADERS = ['assister_id', 'date', 'dunker_id', 'game_id', 'make', 'quarter',\n",
    "       'team', 'time', 'id', 'season']\n",
    "\n",
    "def read(data_type):\n",
    "    if data_type == \"players\":\n",
    "        path = os.path.join(\"processed\", \"all_players.csv\")\n",
    "    elif data_type == \"dunks\":\n",
    "        path = os.path.join(\"processed\", \"all_dunks.csv\")\n",
    "    data = pd.DataFrame.from_csv(path)\n",
    "    return data\n",
    "\n",
    "def aggregate_and_annotate(players, dunks):\n",
    "\n",
    "    def find_player_stats_for_season(row):\n",
    "        dunker_id = row[\"dunker_id\"]\n",
    "        season = row[\"season\"]\n",
    "        stats = players[(players[\"id\"] == dunker_id) & (players[\"season\"] == season)]\n",
    "        print list(stats.ix[0,:])\n",
    "\n",
    "    dunks[\"miss\"] = dunks.make.map(lambda x: x==0)\n",
    "    \n",
    "    player_dunks_by_years = []\n",
    "    team_dunks_by_years = []\n",
    "    for season in dunks.season.unique():\n",
    "        df = dunks[dunks.season == season].groupby(\"dunker_id\").sum().ix[:, [\"make\", \"miss\"]]\n",
    "        df[\"season\"] = season\n",
    "        player_dunks_by_years.append(df)\n",
    "        \n",
    "        df = dunks[dunks.season == season].groupby(\"team\").sum().ix[:, [\"make\", \"miss\"]]\n",
    "        df[\"season\"] = season\n",
    "        team_dunks_by_years.append(df)\n",
    "        \n",
    "    p_df = pd.concat(player_dunks_by_years)\n",
    "    t_df = pd.concat(team_dunks_by_years)\n",
    "    \n",
    "    print t_df.head()\n",
    "    \n",
    "    p_df.reset_index(inplace=True)\n",
    "    t_df.reset_index(inplace=True)\n",
    "    \n",
    "    print t_df.head()\n",
    "    \n",
    "    t_df.to_csv(os.path.join(\"processed\",\"team_dunk_totals.csv\"))\n",
    "    \n",
    "    stats = []\n",
    "    for i in np.arange(len(p_df)):\n",
    "        dunker_id = p_df.ix[i,\"dunker_id\"]\n",
    "        season = p_df.ix[i,\"season\"]\n",
    "        stats.append(players[(players[\"id\"] == dunker_id) & (players[\"season\"] == season)])\n",
    "    \n",
    "    stats_df = pd.concat(stats)\n",
    "\n",
    "    stats_df.rename(columns={\"id\":\"dunker_id\"}, inplace=True)\n",
    "    stats_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    df = pd.concat([stats_df, p_df.drop([\"season\", \"dunker_id\"], axis=1)], axis=1, join=\"inner\")\n",
    "    df.to_csv(os.path.join(\"processed\",\"player_dunk_totals.csv\"))\n",
    "    \n",
    "    \n",
    "    return df, t_df\n",
    "\n",
    "def summarize_player_dunk_stats(df):\n",
    "    dunk_percentage = df[\"make\"]/(df[\"make\"] + df[\"miss\"])\n",
    "    dunks_per_game = df[\"make\"]/df[\"g\"]\n",
    "    dunks_per_minute = df[\"make\"]/df[\"mp\"]\n",
    "    dunks_per_fg2 = df[\"make\"]/df[\"fg2\"]\n",
    "    \n",
    "    df = pd.concat([dunk_percentage, dunks_per_game, dunks_per_minute, dunks_per_fg2, df[\"season\"], df[\"dunker_id\"], df[\"first_name\"], df[\"last_name\"], df[\"teams\"]], axis=1)\n",
    "    df.columns = [\"dunk_pct\", \"dpg\", \"dpm\", \"dpfg2\", \"season\", \"dunker_id\", \"first_name\", \"last_name\", \"teams\"]\n",
    "    df.to_csv(\"player_dunk_summary.csv\")\n",
    "    \n",
    "def summarize_team_dunk_stats(df):\n",
    "    dunk_percentage = df[\"make\"]/(df[\"make\"] + df[\"miss\"])\n",
    "    \n",
    "    df = pd.concat([df, dunk_percentage], axis=1)\n",
    "    col_list = df.columns.tolist()\n",
    "    print col_list\n",
    "    df.rename(columns={0:\"dunk_pct\"}, inplace=True)\n",
    "    print df.head()\n",
    "    df.to_csv(\"team_dunk_summary.csv\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    players = read(\"players\")\n",
    "    dunks = read(\"dunks\")\n",
    "\n",
    "    dunks = dunks.ix[:, DUNK_HEADERS]\n",
    "    players = players.ix[:, PLAYER_HEADERS]\n",
    "\n",
    "    df, t_df = aggregate_and_annotate(players, dunks)\n",
    "    summarize_player_dunk_stats(df)\n",
    "    summarize_team_dunk_stats(t_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(os.path.join(\"team_dunk_summary.csv\"))\n",
    "team_dunks = df.groupby(\"team\").mean().sort_values(\"make\", ascending=False).drop(\"season\", axis=1)\n",
    "\n",
    "print team_dunks\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(np.arange(len(team_dunks)), team_dunks[\"make\"], tick_label=team_dunks.index)\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculating dunks per minute played for Nicolas Batum\n",
    "df = pd.DataFrame.from_csv(os.path.join(\"processed\",\"player_dunk_totals.csv\"))\n",
    "\n",
    "dpm = df[(df[\"first_name\"] == \"Nicolas\") & (df[\"last_name\"] == \"Batum\")].apply(lambda x: x[\"make\"]/x[\"mp\"], axis=1)\n",
    "\n",
    "%matplotlib inline\n",
    "nb_dunks = df[(df[\"first_name\"] == \"Nicolas\") & (df[\"last_name\"] == \"Batum\")]\n",
    "dpm.index = nb_dunks.season\n",
    "\n",
    "dpm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculating dunks per games played for Nicolas Batum\n",
    "df = pd.DataFrame.from_csv(os.path.join(\"processed\",\"player_dunk_totals.csv\"))\n",
    "\n",
    "dpg = df[(df[\"first_name\"] == \"Nicolas\") & (df[\"last_name\"] == \"Batum\")].apply(lambda x: x[\"make\"]/x[\"g\"], axis=1)\n",
    "\n",
    "%matplotlib inline\n",
    "nb_dunks = df[(df[\"first_name\"] == \"Nicolas\") & (df[\"last_name\"] == \"Batum\")]\n",
    "dpg.index = nb_dunks.season\n",
    "\n",
    "dpg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"dunk_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df[\"first_name\"] == \"Marquese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dw_dunks = df[(df[\"first_name\"] == \"Dwyane\") & (df[\"last_name\"] == \"Wade\")]\n",
    "lbj_dunks = df[(df[\"first_name\"] == \"LeBron\") & (df[\"last_name\"] == \"James\")]\n",
    "cb_dunks = df[(df[\"first_name\"] == \"Chris\") & (df[\"last_name\"] == \"Bosh\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(dw_dunks.ix[:,[\"dpm\"]], label=\"DW\")\n",
    "ax.plot(lbj_dunks.ix[:,[\"dpm\"]], label=\"LBJ\")\n",
    "ax.plot(cb_dunks.ix[:,[\"dpm\"]], label=\"CB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ki_dunks = df[(df[\"first_name\"] == \"Kyrie\") & (df[\"last_name\"] == \"Irving\")]\n",
    "lbj_dunks = df[(df[\"first_name\"] == \"LeBron\") & (df[\"last_name\"] == \"James\")]\n",
    "kl_dunks = df[(df[\"first_name\"] == \"Kevin\") & (df[\"last_name\"] == \"Love\")]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(ki_dunks.ix[:,[\"dpm\"]], label=\"KI\")\n",
    "ax.plot(lbj_dunks.ix[:,[\"dpm\"]], label=\"LBJ\")\n",
    "ax.plot(kl_dunks.ix[:,[\"dpm\"]], label=\"KL\", )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_player_summary(stat, dunker_names = None, dunker_ids = None):\n",
    "    dfs = []\n",
    "    df = pd.DataFrame.from_csv(\"dunk_summary.csv\")\n",
    "    if dunker_names != None and len(dunker_names) != 0:\n",
    "        for dunker_name in dunker_names:\n",
    "            first_name, last_name = dunker_name.split(\" \", 1)\n",
    "            try:\n",
    "                dfs.append(df[(df[\"first_name\"] == first_name) & (df[\"last_name\"] == last_name)])\n",
    "            except Exception as err:\n",
    "                print err.message\n",
    "    elif dunker_ids != None and len(dunker_ids) != 0:\n",
    "        for dunker_id in dunker_ids:\n",
    "            try:\n",
    "                dfs.append(df[(df[\"dunker_id\"] == dunker_id)])\n",
    "            except Exception as err:\n",
    "                print err.message\n",
    "    \n",
    "    try:\n",
    "        seasons = np.unique(np.concatenate([df[\"season\"] for df in dfs]))\n",
    "    except ValueError:\n",
    "        print \"couldn't find any dunk records for the names or ids passed in\"\n",
    "        raise\n",
    "        \n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    if stat == \"dunk_pct\":\n",
    "        ax.set_ylim(0, 1.1)\n",
    "    for dunks in dfs:\n",
    "        dpms= []\n",
    "        for season in seasons:\n",
    "            dpms.append(dunks[dunks[\"season\"] == season][stat].values)\n",
    "        try:\n",
    "            ax.plot(pd.DataFrame(dpms, index=seasons), label=dunks[\"first_name\"].values[0]+\" \"+dunks[\"last_name\"].values[0])\n",
    "        except Exception as err:\n",
    "            print \"one of the passed names or ids was not accurate\"\n",
    "    ax.legend(loc=(1.05, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_player_summary(dunker_names=[\"Marquese Chriss\"], stat=\"dpfg2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_team_trends(stat, teams=None):\n",
    "    df = pd.DataFrame.from_csv(\"dunk_summary.csv\")\n",
    "    \n",
    "    if teams == None:\n",
    "        all_teams = [\"\".join([c if c not in [\"'\", \"u\", \"]\", \"[\", \" \"] else \"\" for c in tl]).split(',') for tl in df[\"teams\"].values]\n",
    "        teams = np.unique(np.concatenate(all_teams))\n",
    "    \n",
    "    dfs = []\n",
    "    for team in teams:\n",
    "        team_stats = []\n",
    "        for row in np.arange(len(df.index)):\n",
    "            team_list = \"\".join([c if c not in [\"'\", \"u\", \"]\", \"[\"] else \"\" for c in df.ix[row, \"teams\"]]).split(',')\n",
    "            if team in team_list:\n",
    "                team_stats.append(df.ix[row, :])\n",
    "        team_df = pd.DataFrame(team_stats)\n",
    "        team_df = team_df.groupby(\"season\").mean()\n",
    "        team_df[\"team\"] = team\n",
    "        dfs.append(team_df)\n",
    "\n",
    "    print pd.concat(dfs).sort_values(stat)\n",
    "    top_teams = pd.concat(dfs).groupby(\"team\").mean().sort_values(stat, ascending=False)[:10].index\n",
    "\n",
    "    fig = plt.figure(figsize = (10,20))\n",
    "    ax = plt.subplot(111)\n",
    "    if stat == \"dunk_pct\":\n",
    "        ax.set_ylim(0, 1.1)\n",
    "    ax.set_ylim(.5, 1.1)\n",
    "    for i in np.arange(len(dfs)):\n",
    "        df = dfs[i]\n",
    "        team = teams[i]\n",
    "        if team in top_teams:\n",
    "            try:\n",
    "                ax.plot(list(df.index), df.ix[:, stat], label=team)\n",
    "            except Exception as err:\n",
    "                print \"one of the passed names or ids was not accurate\"\n",
    "    ax.legend(loc=(1.05, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_teams(stat, teams=None):\n",
    "    df = pd.DataFrame.from_csv(\"dunk_summary.csv\")\n",
    "\n",
    "    if teams == None:\n",
    "        all_teams = [\"\".join([c if c not in [\"'\", \"u\", \"]\", \"[\", \" \"] else \"\" for c in tl]).split(',') for tl in df[\"teams\"].values]\n",
    "        teams = np.unique(np.concatenate(all_teams))\n",
    "\n",
    "    dfs = []\n",
    "    for team in teams:\n",
    "        team_stats = []\n",
    "        for row in np.arange(len(df.index)):\n",
    "            team_list = \"\".join([c if c not in [\"'\", \"u\", \"]\", \"[\"] else \"\" for c in df.ix[row, \"teams\"]]).split(',')\n",
    "            if team in team_list:\n",
    "                team_stats.append(df.ix[row, :])\n",
    "        team_df = pd.DataFrame(team_stats)\n",
    "        team_df = team_df.groupby(\"season\").mean()\n",
    "        team_df[\"team\"] = team\n",
    "        dfs.append(team_df)\n",
    "\n",
    "    top_teams = pd.concat(dfs).sort_values(stat)\n",
    "    top_teams.reset_index(inplace=True)\n",
    "    \n",
    "    fig = plt.figure(figsize = (100,10))\n",
    "    ax = plt.subplot(111)\n",
    "    if stat == \"dunk_pct\":\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "    print top_teams\n",
    "    tick_labels = [str(top_teams.season[i])+\" \"+top_teams.ix[i, \"team\"] for i in np.arange(len(top_teams.index))]\n",
    "    ax.bar(np.arange(len(top_teams)), top_teams.ix[:, stat], tick_label=tick_labels)\n",
    "    ax.set_xticklabels(ax.get_xmajorticklabels(), rotation=90)\n",
    "    ax.legend(loc=(1.05, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(\"dunk_summary.csv\")\n",
    "df[df[\"season\"] == 2016 & (\"POR\" in df[\"teams\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_teams(stat=\"dpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_team_trends(stat = \"dunk_pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cp3_dunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(data_type):\n",
    "    if data_type == \"players\":\n",
    "        path = os.path.join(\"processed\", \"all_players.csv\")\n",
    "    elif data_type == \"dunks\":\n",
    "        path = os.path.join(\"processed\", \"all_dunks.csv\")\n",
    "    data = pd.DataFrame.from_csv(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = read(\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[(df[\"id\"] == \"walljo01\") & (df[\"season\"] == 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "db = dataset.connect(\"sqlite:///dunks.db\")\n",
    "\n",
    "table = db[\"dunks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results =  table.find()\n",
    "for i in results:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scraper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scraper.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import collections\n",
    "import json\n",
    "import bs4\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import wptools\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from fuzzywuzzy import process\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import dataset\n",
    "\n",
    "\n",
    "\n",
    "def scrape_all(year):\n",
    "\n",
    "    def players_for_year(year, force_query=False):\n",
    "        # scrapes basketball-reference.com\n",
    "\n",
    "        def request_players_from_web(year):\n",
    "            player_stat_page = \"http://www.basketball-reference.com/leagues/NBA_{0}_totals.html\".format(str(year+1))\n",
    "            r = urllib2.urlopen(player_stat_page)\n",
    "            return r\n",
    "\n",
    "        def backup_players_to_disk(year, df):\n",
    "            if not os.path.exists(\"data/\"+str(year)):\n",
    "                os.makedirs(\"data/\"+str(year))\n",
    "\n",
    "            with open(os.path.join(\"data\",str(year),\"player_list.csv\"), \"w\") as f:\n",
    "                df.to_csv(f)\n",
    "\n",
    "        def parse_player_page(page):\n",
    "            table = bs4.BeautifulSoup(page, \"lxml\").find(\"div\", {\"id\":\"div_totals_stats\"}).table\n",
    "            stat_dict = collections.defaultdict(list)\n",
    "            for row in table.find_all(\"tr\", {\"class\":[\"full_table\", \"partial_table\"]})[1:]:\n",
    "                if row.find(\"td\")[\"data-append-csv\"] not in stat_dict[\"player_id\"]:\n",
    "\n",
    "                    for col in row.find_all(\"td\"):\n",
    "                        if col.has_attr(\"data-stat\"):\n",
    "                            stat_name = col[\"data-stat\"]\n",
    "\n",
    "                            # Special behavior for managing team data\n",
    "                            if stat_name == \"team_id\":\n",
    "                                if col.text != \"TOT\":\n",
    "                                    #this player played on just one team this season.\n",
    "                                    stat_dict[\"teams\"].append([col.text])\n",
    "                                else:\n",
    "                                    #this player played on multiple teams, we'll add them later.\n",
    "                                    stat_dict[\"teams\"].append([])\n",
    "                            # Special behavior for the player name data\n",
    "                            elif stat_name == \"player\":\n",
    "                                player = col[\"csk\"]\n",
    "                                stat_dict[\"first_name\"].append(player.split(\",\")[1])\n",
    "                                stat_dict[\"last_name\"].append(player.split(\",\")[0])\n",
    "                                stat_dict[\"player_id\"].append(col[\"data-append-csv\"])\n",
    "                            # With everything else just use the stat name\n",
    "                            else:\n",
    "                                stat_dict[stat_name].append(col.text)\n",
    "                else:\n",
    "                    # we've recorded this player's information before, we just need to complete his list of teams.\n",
    "                    index = stat_dict[\"player_id\"].index(row.find(\"td\")[\"data-append-csv\"])\n",
    "                    stat_dict[\"teams\"][index].append(row.find(\"td\", {\"data-stat\":\"team_id\"}).a.text)\n",
    "            df = pd.DataFrame(stat_dict)\n",
    "            df.set_index(\"player_id\", drop=True, inplace=True)\n",
    "            return df\n",
    "\n",
    "\n",
    "        if force_query:\n",
    "            # We want to get the remote copy, regardless if we have it already.\n",
    "            page = request_players_from_web(year)\n",
    "            df = parse_player_page(page)\n",
    "            backup_players_to_disk(year, df)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                # Just try to get the local copy, if it exists\n",
    "                with open(os.path.join(str(year), \"player_list.csv\"), \"r\") as f:\n",
    "                    return pd.DataFrame.from_csv(f)\n",
    "            except IOError:\n",
    "                # We don't have a local copy\n",
    "                page = request_players_from_web(year)\n",
    "                df = parse_player_page(page)\n",
    "                backup_players_to_disk(year, df)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def scrape_pbp(year, players):\n",
    "        # scrapes ESPN and wikipedia\n",
    "\n",
    "        ###### Helper Methods #######\n",
    "\n",
    "        def getPlayerId(last_name, first_name, players):\n",
    "            # print \"searching for: \" + first_name + \" \" + last_name\n",
    "\n",
    "            basic_search = players[(players[\"last_name\"] == last_name) & (players[\"first_name\"] == first_name)]\n",
    "            if not basic_search.empty:\n",
    "                # print \"found: \" + str(basic_search.index[0])\n",
    "                return basic_search.index[0]\n",
    "            else:\n",
    "                full_names = pd.Series(player_list[\"first_name\"]+\" \"+player_list[\"last_name\"]).values\n",
    "                name_match = process.extract(first_name+last_name, full_names, limit=1)[0]\n",
    "                index = np.where(full_names == name_match[0])\n",
    "                # print \"fuzzywuzzy found: \" + str(players.index[index[0][0]])\n",
    "                return players.index[index[0][0]]\n",
    "\n",
    "        def parse_dunk(dunk, players, game_id, title, teams):\n",
    "#             print dunk\n",
    "            if (\"missed\" in dunk) or (\"made\" in dunk):\n",
    "#                 print \"old\"\n",
    "                # Old style\n",
    "                if \"missed\" in dunk:\n",
    "                    dunker_name = dunk.split(\"miss\")[0]\n",
    "                    make = 0\n",
    "                    # And he missed it...\n",
    "                elif \"made\" in dunk:\n",
    "                    dunker_name = dunk.split(\"made\")[0]\n",
    "                    make = 0\n",
    "                elif \"alley-oop\" in dunk:\n",
    "                    dunker_name = dunk.split(\"alley-oop\")[0]\n",
    "                    make = 1\n",
    "                elif \"'s\" in dunk:\n",
    "                    # rare possesive form of play-by-play, \"player 1 blocks player 2's slam dunk\"\n",
    "                    # Since the dunk was blocked, we'll just ignore it for now.\n",
    "                    return\n",
    "                else:\n",
    "#                     print \"can't find name\"\n",
    "                    return\n",
    "            else:\n",
    "#                 print \"new\"\n",
    "                if \"miss\" in dunk:\n",
    "                    # And he missed it...\n",
    "                    dunker_name = dunk.split(\"miss\")[0]\n",
    "                    make = 0\n",
    "\n",
    "                elif \"make\" in dunk:\n",
    "                    # And he made it...\n",
    "                    dunker_name = dunk.split(\"make\")[0]\n",
    "                    make = 1\n",
    "                elif \"alley-oop\" in dunk:\n",
    "                    dunker_name = dunk.split(\"alley-oop\")[0]\n",
    "                    make = 1\n",
    "                elif \"'s\" in dunk:\n",
    "                    # rare possesive form of play-by-play, \"player 1 blocks player 2's slam dunk\"\n",
    "                    # Since the dunk was blocked, we'll just ignore it for now.\n",
    "                    return\n",
    "                else:\n",
    "#                     print \"can't find name\"\n",
    "                    return\n",
    "\n",
    "            # Try getting a last name for player, some people don't have these\n",
    "            if len(dunker_name.split(\" \", 1)) == 2:\n",
    "                last_name = dunker_name.split(\" \", 1)[1].strip()\n",
    "            else:\n",
    "                last_name = \"\"\n",
    "\n",
    "            # Fetch the playerId from the passed in player dataframe.\n",
    "            first_name = dunker_name.split(\" \", 1)[0].strip()\n",
    "\n",
    "            if len(first_name+last_name) != 0:\n",
    "                player_id = getPlayerId(last_name, first_name, players)\n",
    "            else:\n",
    "                player_id = np.NaN\n",
    "\n",
    "            # Add quarter to record\n",
    "            quarter = q_id[-1]\n",
    "\n",
    "            # Add data to dunk record\n",
    "            try:\n",
    "                date_from_title = title.text.split(\" - \")[2].strip().encode(\"ascii\", \"ignore\")\n",
    "                date = datetime.datetime.strptime(date_from_title, \"%B %d, %Y\")\n",
    "\n",
    "                day = date.day\n",
    "                month = date.month\n",
    "                year = date.year\n",
    "\n",
    "            except IndexError:\n",
    "#                 print \"Could not get date for game\"\n",
    "\n",
    "                day = np.NaN\n",
    "                month = np.NaN\n",
    "                year = np.NaN\n",
    "\n",
    "            # Add in-game time to dunk record\n",
    "            time_stamp = tr.find(\"td\", {\"class\":\"time-stamp\"}).text\n",
    "            time = datetime.datetime.strptime(time_stamp, \"%M:%S\").time()\n",
    "\n",
    "            minute = time.minute\n",
    "            second = time.second\n",
    "\n",
    "            ptrn = re.compile(\"\\([\\w\\s]*\\)\")\n",
    "            # Add assist to dunk record\n",
    "            if re.findall(ptrn, dunk):\n",
    "                assist = re.findall(ptrn, dunk)[0]\n",
    "                full_name = assist.strip(\"(\").strip(\")\").split(\"assists\")[0].strip()\n",
    "                first_name = full_name.split(\" \")[0].strip()\n",
    "                if len(full_name.split(\" \")) == 2:\n",
    "                    last_name = full_name.split(\" \")[1].strip()\n",
    "                else:\n",
    "                    last_name = \"\"\n",
    "\n",
    "                if len(first_name+last_name) != 0:\n",
    "                    a_player_id = getPlayerId(last_name, first_name, players)\n",
    "                else:\n",
    "                    a_player_id = \"\"\n",
    "            elif \"assisted\" in dunk:\n",
    "                full_name = dunk.lower().split(\"assisted by\")[1].strip()\n",
    "                first_name = full_name.split(\" \")[0].strip()\n",
    "                if len(full_name.split(\" \")) == 2:\n",
    "                    last_name = full_name.split(\" \")[1].strip()\n",
    "                else:\n",
    "                    last_name = \"\"\n",
    "\n",
    "                if len(first_name+last_name) != 0:\n",
    "                    a_player_id = getPlayerId(last_name, first_name, players)\n",
    "                else:\n",
    "                    a_player_id = \"\"\n",
    "            else:\n",
    "                a_player_id = \"\"\n",
    "\n",
    "\n",
    "            try:\n",
    "                team_id = tr.find(\"img\")[\"src\"].split(\"/500/\")[1].split(\".png\")[0].upper()\n",
    "            except IndexError:\n",
    "#                 print \"couldn't find logo for team\"\n",
    "                team_id = predict_team(player_id, a_player_id, players, teams)\n",
    "                \n",
    "            dunk_id = str(str(game_id)+str(quarter)+str(minute)+str(second))\n",
    "\n",
    "            return dict(day=day,\n",
    "            month=month,\n",
    "            year=year,\n",
    "            minute=minute,\n",
    "            second=second,\n",
    "            game_id=game_id,\n",
    "            quarter=quarter,\n",
    "            make=make,\n",
    "            player_id=player_id,\n",
    "            assister_id=a_player_id,\n",
    "            team=team_id,\n",
    "            id=dunk_id\n",
    "            )\n",
    "\n",
    "        def season_duration(year):\n",
    "\n",
    "            print \"looking for season for year: \" + str(year)\n",
    "            page_title = \"{0}%E2%80%93{1}_NBA_season\".format(str(year), str(year+1)[2:])\n",
    "\n",
    "\n",
    "            r = wptools.page(page_title).get_parse().infobox[\"duration\"]\n",
    "\n",
    "            start_date = 0\n",
    "            end_date = 0\n",
    "\n",
    "            dates_string = r.encode('ascii','ignore')\n",
    "            p = re.compile(\"[A-Za-z]+\\s[0-9]+,\\s[0-9]{4}\")\n",
    "            dates = p.findall(dates_string)\n",
    "            start_date = datetime.datetime.strptime(dates[0], \"%B %d, %Y\")\n",
    "            end_date = datetime.datetime.strptime(dates[1], \"%B %d, %Y\")\n",
    "\n",
    "            return start_date, end_date\n",
    "\n",
    "        def predict_team(dunker, assister, player_list, teams):\n",
    "            \n",
    "            dunker_teams = player_list.ix[dunker, \"teams\"]\n",
    "            if type(dunker_teams) == list:\n",
    "                dunker_teams = \",\".join(dunker_teams)\n",
    "            \n",
    "            if assister:\n",
    "                \n",
    "                assister_teams = player_list.ix[assister, \"teams\"]\n",
    "                if type(assister_teams) == list:\n",
    "                    assister_teams = \",\".join(assister_teams)\n",
    "                \n",
    "                for t in teams:\n",
    "                    if t in dunker_teams and t in assister_teams:\n",
    "                        return t\n",
    "            else:\n",
    "                for t in teams:\n",
    "                    if t in dunker_teams:\n",
    "                        return t\n",
    "                    \n",
    "            return np.NaN\n",
    "\n",
    "\n",
    "\n",
    "        def parse_schedule_page(page, start_date, end_date):\n",
    "\n",
    "            def year_to_espn_season_code(year):\n",
    "                base = (20, 2000)\n",
    "                diff = year - base[1]\n",
    "                code_for_year = base[0] + diff\n",
    "                return code_for_year\n",
    "\n",
    "            soup = bs4.BeautifulSoup(page)\n",
    "            games = soup.find_all(\"a\", {\"name\":\"&lpos=nba:schedule:score\"})\n",
    "            links = []\n",
    "            for game in games:\n",
    "                game_id = game[\"href\"].split(\"=\")[1]\n",
    "                game_month = int(game_id[2:4])\n",
    "                game_day = int(game_id[4:6])\n",
    "                game_year_code = int(game_id[0:2])\n",
    "#                 print game_id, game_month, game_day, game_year_code, year_to_espn_season_code(start_date.year)\n",
    "                if game_year_code == year_to_espn_season_code(start_date.year):\n",
    "                    # Beginning of Season\n",
    "                    if game_month == start_date.month:\n",
    "                        if game_day > start_date.day or game_day == start_date.day:\n",
    "                            links.append(game_id)\n",
    "                    elif game_month > start_date.month:\n",
    "                        links.append(game_id)\n",
    "                else:\n",
    "                    # End of Season\n",
    "                    if game_month == end_date.month:\n",
    "                        if game_day < end_date.day or game_day == end_date.day:\n",
    "                            links.append(game_id)\n",
    "                    elif game_month < end_date.month:\n",
    "                        links.append(game_id)\n",
    "            print \"games found: \" + str(len(links))\n",
    "            return links\n",
    "\n",
    "        def request_schedule_page(date):\n",
    "            date_param = date.strftime(\"%Y%m%d\")\n",
    "\n",
    "            ROOT_URL = \"http://www.espn.com/nba/schedule/_/date/{date}\"\n",
    "            GAME_ROOT_URL = \"http://www.espn.com/nba/playbyplay?gameId={0}\"\n",
    "\n",
    "            r = urllib2.urlopen(ROOT_URL.format(date=date_param)).read()\n",
    "\n",
    "            return r\n",
    "\n",
    "        \n",
    "        def get_game_ids_for_season(season):\n",
    "            print \"looking for season for year: \" + str(year)\n",
    "            page_title = \"{0}%E2%80%93{1}_NBA_season\".format(str(year), str(year+1)[2:])\n",
    "\n",
    "            r = wptools.page(page_title).get_parse().infobox[\"duration\"]\n",
    "\n",
    "            start_date = 0\n",
    "            end_date = 0\n",
    "\n",
    "            dates_string = r.encode('ascii','ignore')\n",
    "            p = re.compile(\"[A-Za-z]+\\s[0-9]+,\\s[0-9]{4}\")\n",
    "            dates = p.findall(dates_string)\n",
    "            start_date = datetime.datetime.strptime(dates[0], \"%B %d, %Y\")\n",
    "            end_date = datetime.datetime.strptime(dates[1], \"%B %d, %Y\")\n",
    "            \n",
    "            # ESPN starts using sequential game_ids starting Oct 2012, making it very easy to iterate through all games.\n",
    "            if start_date > datetime.datetime.strptime(\"October, 2012\", \"%B, %Y\"):\n",
    "                print \"after 2012\"\n",
    "                r = request_schedule_page(start_date)\n",
    "\n",
    "                soup = bs4.BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "                indices = []\n",
    "                pbp_path = \"data/\"+str(year)+\"/pbp_reg\"\n",
    "\n",
    "                if not os.path.exists(pbp_path):\n",
    "                    os.makedirs(pbp_path)\n",
    "\n",
    "                dataset_path = \"data/\"+str(year)+\"/datasets\"\n",
    "                if not os.path.exists(dataset_path):\n",
    "                    os.makedirs(dataset_path)\n",
    "\n",
    "                first_game_id = \"\"\n",
    "                for tr in soup.find(\"div\", {\"id\":\"sched-container\"}).find_all(\"tr\"):\n",
    "                    if tr.find(\"a\", {\"name\":\"&lpos=nba:schedule:score\"}) != None:\n",
    "                        first_game_id = tr.find(\"a\", {\"name\":\"&lpos=nba:schedule:score\"})[\"href\"].split(\"=\")[1]\n",
    "                        break\n",
    "\n",
    "                if year == 2011:\n",
    "                    reg_season_games = (66*30)/2\n",
    "                elif year == 1998:\n",
    "                    reg_season_games = (50*29)/2\n",
    "                else:\n",
    "                    reg_season_games = (82*30)/2\n",
    "                return np.arange(int(first_game_id), int(first_game_id)+reg_season_games)\n",
    "            \n",
    "            else:\n",
    "                print \"before 2012\"\n",
    "                duration = end_date - start_date\n",
    "\n",
    "                weeks_in_season = duration.days//7\n",
    "\n",
    "                dataset_path = \"data/\"+str(year)+\"/datasets\"\n",
    "                if not os.path.exists(dataset_path):\n",
    "                    os.makedirs(dataset_path)\n",
    "\n",
    "                game_ids = []\n",
    "                for week in np.arange(0, weeks_in_season+1):\n",
    "                    time.sleep(np.random.randint(2,7))\n",
    "                    r = request_schedule_page(start_date+datetime.timedelta(days=week*7))\n",
    "                    def year_to_espn_season_code(year):\n",
    "                        base = (20, 2000)\n",
    "                        diff = year - base[1]\n",
    "                        code_for_year = base[0] + diff\n",
    "                        return code_for_year\n",
    "\n",
    "                    soup = bs4.BeautifulSoup(r)\n",
    "                    games = soup.find_all(\"a\", {\"name\":\"&lpos=nba:schedule:score\"})\n",
    "                    for game in games:\n",
    "                        game_id = game[\"href\"].split(\"=\")[1]\n",
    "                        game_month = int(game_id[2:4])\n",
    "                        game_day = int(game_id[4:6])\n",
    "                        game_year_code = int(game_id[0:2])\n",
    "                        print game_id, game_month, game_day, game_year_code, year_to_espn_season_code(start_date.year)\n",
    "                        if game_year_code == year_to_espn_season_code(start_date.year):\n",
    "                            # Beginning of Season\n",
    "                            if game_month == start_date.month:\n",
    "                                if game_day > start_date.day or game_day == start_date.day:\n",
    "                                    game_ids.append(game_id)\n",
    "                            elif game_month > start_date.month:\n",
    "                                game_ids.append(game_id)\n",
    "                        else:\n",
    "                            # End of Season\n",
    "                            if game_month == end_date.month:\n",
    "                                if game_day < end_date.day or game_day == end_date.day:\n",
    "                                    game_ids.append(game_id)\n",
    "                            elif game_month < end_date.month:\n",
    "                                game_ids.append(game_id)\n",
    "                return game_ids\n",
    "        \n",
    "        ###### END OF HELPER METHODS ######\n",
    "\n",
    "        db = dataset.connect(\"sqlite:///dunks.db\")\n",
    "        table = db[\"dunks\"]\n",
    "        \n",
    "        GAME_ROOT_URL = \"http://www.espn.com/nba/playbyplay?gameId={0}\"            \n",
    "        \n",
    "        game_ids_path = os.path.join(\"data\", str(year), \"game_ids\")\n",
    "        \n",
    "        import pickle\n",
    "        if not os.path.exists(game_ids_path):\n",
    "            print year\n",
    "            game_ids = get_game_ids_for_season(year)\n",
    "\n",
    "            with open(game_ids_path, 'wb') as fp:\n",
    "                pickle.dump(game_ids, fp)\n",
    "        else:\n",
    "            with open (game_ids_path, 'rb') as fp:\n",
    "                game_ids = pickle.load(fp)\n",
    "\n",
    "        # Check if we have any dunks from games this season already in the database\n",
    "        results = list(table.find(season=year))\n",
    "        print len(results)\n",
    "        recorded_g_ids = set([int(dunk[\"game_id\"]) for dunk in results])\n",
    "        all_g_ids = set([int(game_id) for game_id in game_ids])\n",
    "        if len(recorded_g_ids) > 0:\n",
    "            missing_g_ids = list(all_g_ids - recorded_g_ids)\n",
    "        else:\n",
    "            missing_g_ids = all_g_ids\n",
    "        \n",
    "        print \"There are \", len(missing_g_ids), \" non-recorded games in the existing dunk data.\"\n",
    "        games_not_found = []\n",
    "        \n",
    "        pbp_path = os.path.join(\"data\", str(year), \"pbp_reg\")\n",
    "\n",
    "        if not os.path.exists(pbp_path):\n",
    "            os.makedirs(pbp_path)\n",
    "    \n",
    "        for game_id in missing_g_ids:  \n",
    "            print game_id\n",
    "            try:\n",
    "                with open(os.path.join(pbp_path, \"pbp_\"+str(game_id)+\".txt\"), \"r\") as f:\n",
    "                    g = f.read()\n",
    "                    g_soup = bs4.BeautifulSoup(g, \"lxml\")\n",
    "                print \"We've got this on disk\"\n",
    "            except IOError:\n",
    "                print \"Don't have this play-by-play yet\"\n",
    "                time.sleep(np.random.randint(2,7))\n",
    "                try:\n",
    "                    g = urllib2.urlopen(GAME_ROOT_URL.format(game_id)).read()\n",
    "                except urllib2.URLError:\n",
    "                    print \"could not get page\"\n",
    "                    games_not_found.append(game_id)\n",
    "                    continue\n",
    "\n",
    "\n",
    "            g_soup = bs4.BeautifulSoup(g, \"lxml\")\n",
    "            with open(os.path.join(pbp_path, \"pbp_\"+str(game_id)+\".txt\"), \"wb\") as f:\n",
    "                f.write(str(g_soup))\n",
    "            try:\n",
    "                title = g_soup.title\n",
    "                print \"Checking for dunks: \", \" \".join(title.text.split(\" - \")[0:3])\n",
    "            except AttributeError:\n",
    "                print \"Something went wrong. Possibly the backed up file did not save properly.\"\n",
    "\n",
    "\n",
    "            play_by_play =  g_soup.find(\"article\", {\"class\":\"play-by-play\"})\n",
    "\n",
    "\n",
    "            teams = [team.text for team in g_soup.find_all(\"span\", {\"class\":\"abbrev\"})]\n",
    "\n",
    "            try:\n",
    "                for acc in play_by_play.find_all(\"li\", {\"class\":\"accordion-item\"}):\n",
    "                    for div in acc.find_all(\"div\"):\n",
    "                        if div.has_attr('id'):\n",
    "                            q_id = div[\"id\"]\n",
    "                    for tr in acc.find_all(\"tr\"):\n",
    "                        details = tr.find(\"td\", {\"class\":\"game-details\"})\n",
    "                        if details != None:\n",
    "                            play = details.string.lower()\n",
    "                            if \"dunk\" in play:\n",
    "                                # This play was a dunk!\n",
    "                                parsed_dict = parse_dunk(play, players, game_id, title, teams)\n",
    "                                if parsed_dict != None:\n",
    "                                    parsed_dict[\"season\"] = year\n",
    "                                    try:\n",
    "                                        table.insert_ignore(parsed_dict, [\"id\"])\n",
    "                                        db.commit()\n",
    "                                        print \"dunk saved\"\n",
    "                                    except Exception as err:\n",
    "                                        db.rollback()\n",
    "                                        print err.message, \"dunk not saved\"\n",
    "                                else:\n",
    "                                    continue\n",
    "            except AttributeError:\n",
    "                print \"Play-by-play parsing failed. Probably got incorrect page.\"\n",
    "                continue\n",
    "\n",
    "    player_list = players_for_year(year)\n",
    "    scrape_pbp(year, player_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Get dunks for any given NBA season')\n",
    "    parser.add_argument('-s', '--season', type=int, nargs='+',\n",
    "                        help='The year to scrape (the year passed represents the beginning of the season)', required=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print args.season\n",
    "    for season in list(args.season):\n",
    "        scrape_all(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
      "5119\n",
      "There are  222  non-recorded games in the existing dunk data.\n",
      "230123009\n",
      "We've got this on disk\n",
      "Checking for dunks:  Nets vs. Warriors Play-By-Play January 23, 2003\n",
      "230205014\n",
      "We've got this on disk\n",
      "Checking for dunks:  Trail Blazers vs. Heat Play-By-Play February 5, 2003\n",
      "230115002\n",
      "We've got this on disk\n",
      "Checking for dunks:  Hawks vs. Celtics Play-By-Play January 15, 2003\n",
      "230123020\n",
      "We've got this on disk\n",
      "Checking for dunks:  Mavericks vs. 76ers Play-By-Play January 23, 2003\n",
      "230122001\n",
      "We've got this on disk\n",
      "Checking for dunks:  Trail Blazers vs. Hawks Play-By-Play January 22, 2003\n",
      "230122002\n",
      "We've got this on disk\n",
      "Checking for dunks:  Bucks vs. Celtics Play-By-Play January 22, 2003\n",
      "230315027\n",
      "We've got this on disk\n",
      "Checking for dunks:  Heat vs. Wizards Play-By-Play March 15, 2003\n",
      "230123029\n",
      "We've got this on disk\n",
      "Checking for dunks:  Kings vs. Grizzlies Play-By-Play January 23, 2003\n",
      "230122008\n",
      "We've got this on disk\n",
      "Checking for dunks:  76ers vs. Pistons Play-By-Play January 22, 2003\n",
      "230122011\n",
      "We've got this on disk\n",
      "Checking for dunks:  Raptors vs. Pacers Play-By-Play January 22, 2003\n",
      "230122013\n",
      "We've got this on disk\n",
      "Checking for dunks:  Warriors vs. Lakers Play-By-Play January 22, 2003\n",
      "230122014\n",
      "We've got this on disk\n",
      "Checking for dunks:  Suns vs. Heat Play-By-Play January 22, 2003\n",
      "230122016\n",
      "We've got this on disk\n",
      "Checking for dunks:  SuperSonics vs. Timberwolves Play-By-Play January 22, 2003\n",
      "230122018\n",
      "We've got this on disk\n",
      "Checking for dunks:  Nuggets vs. Knicks Play-By-Play January 22, 2003\n",
      "230115003\n",
      "We've got this on disk\n",
      "Checking for dunks:  Lakers vs. Hornets Play-By-Play January 15, 2003\n",
      "221119016\n",
      "We've got this on disk\n",
      "Checking for dunks:  Grizzlies vs. Timberwolves Play-By-Play November 19, 2002\n",
      "230121005\n",
      "We've got this on disk\n",
      "Checking for dunks:  Magic vs. Cavaliers Play-By-Play January 21, 2003\n",
      "230121006\n",
      "We've got this on disk\n",
      "Checking for dunks:  Rockets vs. Mavericks Play-By-Play January 21, 2003\n",
      "230201011\n",
      "We've got this on disk\n",
      "Checking for dunks:  Celtics vs. Pacers Play-By-Play February 1, 2003\n",
      "221203004\n",
      "We've got this on disk\n",
      "Checking for dunks:  Hornets vs. Bulls Play-By-Play December 3, 2002\n",
      "230206015\n",
      "We've got this on disk\n",
      "Checking for dunks:  SuperSonics vs. Bucks Play-By-Play February 6, 2003\n",
      "221203009\n",
      "We've got this on disk\n",
      "Checking for dunks:  Nuggets vs. Warriors Play-By-Play December 3, 2002\n",
      "221203010\n",
      "We've got this on disk\n",
      "Checking for dunks:  Spurs vs. Rockets Play-By-Play December 3, 2002\n",
      "230120003\n",
      "We've got this on disk\n",
      "Checking for dunks:  Suns vs. Hornets Play-By-Play January 20, 2003\n",
      "221203013\n",
      "We've got this on disk\n",
      "Checking for dunks:  Grizzlies vs. Lakers Play-By-Play December 3, 2002\n",
      "230120008\n",
      "We've got this on disk"
     ]
    }
   ],
   "source": [
    "%run scraper.py -s 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89635"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = dataset.connect(\"sqlite:///dunks.db\")\n",
    "table = db[\"dunks\"]\n",
    "\n",
    "\n",
    "results = table.all()\n",
    "results = list(results)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique([dunk[\"game_id\"] for dunk in list(db[\"dunks\"].find(season=2010))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StatementError",
     "evalue": "(exceptions.ValueError) could not convert string to float:  [SQL: u'UPDATE dunks SET quarter=?, season=?, make=?, team=?, month=?, second=?, year=?, player_id=?, game_id=?, assister_id=?, day=?, minute=? WHERE dunks.id = ?']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatementError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1085-cbbb0ce0f864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"assister_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/dataset/persistence/table.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, row, keys, ensure, types)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_to_clause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mstmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object, *multiparams, **params)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/sql/elements.pyc\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistilled_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         )\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                 None, None)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 util.raise_from_cause(\n\u001b[1;32m   1392\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m                     \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m                 )\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/util/compat.pyc\u001b[0m in \u001b[0;36mraise_from_cause\u001b[0;34m(exception, exc_info)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mcause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpy3k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/engine/base.pyc\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_revalidate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             self._handle_dbapi_exception(\n",
      "\u001b[0;32m//anaconda/envs/python2/lib/python2.7/site-packages/sqlalchemy/engine/default.pyc\u001b[0m in \u001b[0;36m_init_compiled\u001b[0;34m(cls, dialect, connection, dbapi_connection, compiled, parameters)\u001b[0m\n\u001b[1;32m    621\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositiontup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiled_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiled_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatementError\u001b[0m: (exceptions.ValueError) could not convert string to float:  [SQL: u'UPDATE dunks SET quarter=?, season=?, make=?, team=?, month=?, second=?, year=?, player_id=?, game_id=?, assister_id=?, day=?, minute=? WHERE dunks.id = ?']"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    result[\"assister_id\"] = \"\"\n",
    "    table.update(result, [\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunk Dataset.ipynb      database.pyc            player_dunk_summary.csv\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m             dunk.db                 \u001b[34mprocessed\u001b[m\u001b[m\r\n",
      "annotate.ipynb          dunk_summary.csv        scraper.py\r\n",
      "annotate.py             dunks.db                scraper.pyc\r\n",
      "assemble.py             fix_dunks.sql           team_dunk_summary.csv\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                    parser.py               test_scraper.py\r\n",
      "database.py             parser.pyc\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "games_2003 = pickle.load(open(\"data/2003/game_ids\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['231028020', '231028024', '231028013', '231029002', '231029003', '231029007', '231029016', '231029026', '231029004', '231029009', '231029023', '231029008', '231029018', '231029028', '231030010', '231030019', '231030025', '231030021', '231031012', '231031028', '231031029', '231031004', '231031011', '231031014', '231031023', '231031017', '231101001', '231101003', '231101007', '231101016', '231101019', '231101021', '231101022', '231101027', '231101006', '231101009', '231101010', '231101015', '231101024', '231102013', '231103019', '231103022', '231103026', '231103029', '231103001', '231103004', '231103006', '231104011', '231104015', '231104017', '231104024', '231105016', '231105019', '231105020', '231105026', '231105027', '231105008', '231105009', '231105018', '231105022', '231105005', '231106017', '231106028', '231106024', '231107003', '231107007', '231107021', '231107027', '231107002', '231107004', '231107009', '231107011', '231107018', '231107025', '231107008', '231107019', '231108003', '231108022', '231108026', '231108005', '231108010', '231108014', '231108015', '231108024', '231109028', '231109002', '231109008', '231109020', '231109025', '231110005', '231110024', '231110029', '231110004', '231110009', '231111011', '231111016', '231111022', '231111023', '231111027', '231111006', '231111010', '231111012', '231112009', '231112002', '231112003', '231112015', '231112017', '231112019', '231112021', '231112013', '231112014', '231113006', '231113022', '231113004', '231114016', '231114023', '231114002', '231114009', '231114010', '231114011', '231114013', '231114014', '231114017', '231114020', '231114007', '231115001', '231115003', '231115021', '231115027', '231115029', '231115004', '231115005', '231115012', '231115015', '231115018', '231116028', '231116023', '231116013', '231117020', '231117026', '231117001', '231117006', '231117018', '231118005', '231118015', '231118016', '231118021', '231118025', '231118008', '231118017', '231118024', '231119002', '231119007', '231119011', '231119022', '231119026', '231119027', '231119028', '231119010', '231119018', '231119029', '231120006', '231120021', '231121003', '231121007', '231121020', '231121023', '231121026', '231121009', '231121013', '231121022', '231121024', '231121025', '231121005', '231121008', '231122017', '231122001', '231122016', '231122021', '231122006', '231122018', '231123028', '231123023', '231123008', '231123009', '231123025', '231123013', '231124002', '231124019', '231124001', '231124012', '231125007', '231125011', '231125015', '231125022', '231125023', '231125025', '231125006', '231125014', '231126003', '231126016', '231126019', '231126020', '231126021', '231126026', '231126001', '231126013', '231126024', '231127012', '231127011', '231128007', '231128021', '231128022', '231128023', '231128026', '231128029', '231128001', '231128002', '231128013', '231128008', '231128011', '231128019', '231129018', '231129020', '231129025', '231129027', '231129005', '231129006', '231129009', '231129012', '231129014', '231129015', '231130023', '231130013', '231201002', '231201021', '231201026', '231201004', '231201012', '231201018', '231202007', '231202019', '231202020', '231202001', '231202006', '231203003', '231203021', '231203022', '231203025', '231203028', '231203008', '231203009', '231203010', '231203012', '231203017', '231203024', '231204020', '231204006', '231205003', '231205007', '231205022', '231205026', '231205028', '231205029', '231205002', '231205014', '231205017', '231205023', '231205025', '231205019', '231206004', '231206005', '231206006', '231206009', '231206010', '231206014', '231206015', '231206017', '231207012', '231207029', '231207028', '231207023', '231207013', '231207007', '231208003', '231208019', '231208026', '231208004', '231209005', '231209011', '231209016', '231209023', '231209001', '231209008', '231209010', '231209013', '231209014', '231209017', '231210002', '231210015', '231210026', '231210027', '231210029', '231210012', '231210024', '231211005', '231211010', '231211021', '231212020', '231212026', '231212027', '231212002', '231212009', '231212011', '231212013', '231212014', '231212015', '231212008', '231212019', '231213022', '231213029', '231213001', '231213004', '231213005', '231213012', '231213018', '231213024', '231214025', '231214028', '231214020', '231214023', '231214018', '231215002', '231215011', '231215006', '231215012', '231215024', '231216007', '231216016', '231216021', '231216022', '231216027', '231216029', '231216004', '231216014', '231216018', '231217005', '231217011', '231217020', '231217025', '231217001', '231217008', '231217012', '231217017', '231217024', '231217002', '231218016', '231218003', '231218022', '231219019', '231219020', '231219028', '231219029', '231219001', '231219002', '231219010', '231219013', '231219017', '231219025', '231219011', '231220003', '231220007', '231220021', '231220022', '231220004', '231220006', '231220015', '231220018', '231220016', '231221028', '231221002', '231221008', '231221014', '231221023', '231221013', '231222007', '231222020', '231222004', '231223005', '231223015', '231223022', '231223023', '231223025', '231223001', '231223009', '231223010', '231223014', '231223017', '231223018', '231223024', '231225019', '231225023', '231225013', '231226003', '231226007', '231226021', '231226026', '231226027', '231226029', '231226005', '231226009', '231226012', '231226015', '231226022', '231226024', '231226008', '231227001', '231227025', '231227004', '231227006', '231227014', '231227011', '231228012', '231228023', '231228021', '231228024', '231228013', '231228005', '231228007', '231229011', '231229019', '231229026', '231229004', '231229008', '231229009', '231229010', '231229012', '231229017', '231230005', '231230007', '231230016', '231230027', '231230029', '231230006', '231230018', '231231002', '231231008', '231231012', '231231017', '231231010', '240102016', '240102022', '240102027', '240102028', '240102029', '240102002', '240102014', '240102015', '240102017', '240102018', '240102025', '240102008', '240103024', '240103012', '240103029', '240103004', '240103006', '240103008', '240103010', '240103007', '240103011', '240104028', '240104027', '240104023', '240104012', '240104018', '240105002', '240105007', '240105020', '240105025', '240105026', '240105004', '240105010', '240105014', '240106005', '240106011', '240106016', '240106023', '240106017', '240106024', '240107002', '240107003', '240107007', '240107015', '240107020', '240107025', '240107028', '240107008', '240107014', '240107006', '240108018', '240108016', '240109003', '240109006', '240109007', '240109019', '240109020', '240109028', '240109002', '240109004', '240109013', '240109015', '240109025', '240109021', '240110016', '240110026', '240110027', '240110004', '240110009', '240110018', '240110024', '240111028', '240111008', '240111023', '240111012', '240111010', '240112013', '240112009', '240112018', '240112019', '240113003', '240113015', '240113021', '240113023', '240113025', '240113026', '240113027', '240113001', '240113004', '240113012', '240114002', '240114011', '240114008', '240114013', '240114017', '240114018', '240114024', '240114006', '240115003', '240115015', '240115022', '240115026', '240115029', '240115009', '240116007', '240116011', '240116019', '240116021', '240116012', '240116018', '240116023', '240116008', '240117020', '240117010', '240117001', '240117003', '240117022', '240117026', '240117027', '240117004', '240117013', '240117015', '240117017', '240118002', '240118021', '240118007', '240119012', '240119018', '240119027', '240119001', '240119020', '240119008', '240119019', '240119016', '240119029', '240119009', '240119013', '240120005', '240120011', '240120023', '240120026', '240120006', '240120014', '240121003', '240121007', '240121015', '240121028', '240121029', '240121001', '240121012', '240121024', '240121010', '240122005', '240122025', '240122006', '240123003', '240123016', '240123020', '240123029', '240123001', '240123002', '240123004', '240123012', '240123014', '240123015', '240123011', '240123021', '240124022', '240124025', '240124026', '240124027', '240124005', '240124018', '240124024', '240125006', '240125017', '240125004', '240125016', '240125029', '240125008', '240125019', '240126005', '240126007', '240126015', '240126026', '240126027', '240126014', '240127020', '240127025', '240127001', '240127012', '240127018', '240128002', '240128003', '240128005', '240128007', '240128011', '240128026', '240128027', '240128029', '240128009', '240128013', '240128028', '240128010', '240129019', '240129001', '240129024', '240130020', '240130027', '240130028', '240130029', '240130002', '240130009', '240130013', '240130014', '240130015', '240131006', '240131010', '240131001', '240131003', '240131019', '240131022', '240131025', '240131008', '240131018', '240131024', '240131011', '240201027', '240201028', '240201016', '240202003', '240202007', '240202011', '240202021', '240202025', '240202026', '240202029', '240202001', '240202014', '240203016', '240203020', '240203023', '240203006', '240203008', '240203018', '240204002', '240204003', '240204021', '240204026', '240204027', '240204028', '240204001', '240204010', '240204017', '240204005', '240205025', '240205020', '240206003', '240206016', '240206021', '240206026', '240206027', '240206029', '240206002', '240206009', '240206010', '240206023', '240206028', '240206017', '240207014', '240207001', '240207020', '240207021', '240207005', '240207006', '240207015', '240208022', '240208019', '240208011', '240208016', '240208023', '240208009', '240208018', '240208017', '240209005', '240209007', '240209001', '240209010', '240210015', '240210016', '240210022', '240210025', '240210004', '240210006', '240210014', '240210017', '240210021', '240211003', '240211005', '240211019', '240211020', '240211026', '240211029', '240211008', '240211009', '240211010', '240212022', '240212025', '240212004', '240215032', '240217007', '240217011', '240217015', '240217016', '240217023', '240217029', '240217004', '240217010', '240217013', '240217014', '240217018', '240218003', '240218005', '240218019', '240218022', '240218028', '240218008', '240218009', '240218017', '240219016', '240219025', '240219012', '240220019', '240220027', '240220029', '240220004', '240220005', '240220009', '240220013', '240220014', '240220018', '240220028', '240220008', '240221022', '240221004', '240221006', '240221009', '240221014', '240221015', '240221017', '240222018', '240222028', '240222016', '240222011', '240222021', '240222008', '240222025', '240222027', '240222010', '240223005', '240223020', '240223029', '240223014', '240224011', '240224015', '240224019', '240224023', '240224026', '240224001', '240224006', '240224017', '240224024', '240225002', '240225003', '240225007', '240225016', '240225021', '240225025', '240225028', '240225029', '240225004', '240225010', '240226006', '240226027', '240226013', '240227025', '240227002', '240227003', '240227016', '240227019', '240227023', '240227010', '240227012', '240227015', '240227008', '240228017', '240228027', '240228001', '240228029', '240228004', '240228006', '240228024', '240228011', '240229012', '240229028', '240229015', '240229010', '240229017', '240229023', '240229007', '240229020', '240301002', '240301026', '240301027', '240301004', '240301024', '240302007', '240302023', '240302001', '240302006', '240302009', '240302014', '240303003', '240303005', '240303016', '240303019', '240303021', '240303022', '240303027', '240303012', '240303018', '240303024', '240303010', '240304022', '240304014', '240304020', '240305003', '240305016', '240305019', '240305024', '240305026', '240305028', '240305002', '240305009', '240305013', '240306012', '240306014', '240306007', '240306020', '240306021', '240306022', '240306005', '240307010', '240307013', '240307028', '240307027', '240307009', '240307019', '240307025', '240307012', '240307016', '240307007', '240308020', '240308026', '240308001', '240308006', '240309011', '240309023', '240309025', '240309027', '240309029', '240309004', '240309010', '240309014', '240309018', '240310002', '240310003', '240310015', '240310019', '240310022', '240310026', '240310028', '240310008', '240310017', '240310024', '240311010', '240311023', '240312016', '240312020', '240312021', '240312022', '240312029', '240312001', '240312002', '240312014', '240312015', '240312017', '240312024', '240313003', '240313019', '240313021', '240313027', '240313004', '240313010', '240314023', '240314008', '240314028', '240314015', '240314016', '240314005', '240314014', '240314012', '240314007', '240315010', '240315009', '240315013', '240316005', '240316015', '240316021', '240316029', '240316001', '240316014', '240316017', '240316018', '240317002', '240317003', '240317011', '240317027', '240317006', '240317009', '240317012', '240317028', '240318017', '240318029', '240318024', '240319003', '240319006', '240319021', '240319027', '240319028', '240319005', '240319009', '240319011', '240319013', '240319018', '240319008', '240320014', '240320001', '240320021', '240320022', '240320029', '240320004', '240320024', '240321012', '240321017', '240321016', '240321005', '240321027', '240321023', '240321003', '240321025', '240321013', '240322007', '240322011', '240322020', '240322022', '240322018', '240323003', '240323005', '240323016', '240323023', '240323026', '240323029', '240323004', '240324007', '240324019', '240324020', '240324022', '240324025', '240324009', '240324010', '240324013', '240324018', '240324011', '240325001', '240325012', '240325024', '240326003', '240326019', '240326020', '240326029', '240326004', '240326009', '240326013', '240326018', '240326025', '240326002', '240326014', '240327001', '240327022', '240327026', '240327005', '240327008', '240327012', '240327024', '240328028', '240328019', '240328015', '240328023', '240328011', '240328009', '240328002', '240328013', '240329021', '240329001', '240329010', '240329014', '240329017', '240329018', '240329024', '240330007', '240330015', '240330020', '240330006', '240330013', '240331002', '240331011', '240331016', '240331019', '240331026', '240331027', '240331001', '240331008', '240331024', '240331028', '240401006', '240401020', '240401013', '240402007', '240402016', '240402019', '240402026', '240402029', '240402002', '240402004', '240402011', '240402015', '240402025', '240402008', '240402017', '240403020', '240403022', '240403004', '240403005', '240403006', '240404010', '240404013', '240404008', '240404028', '240404027', '240404016', '240404025', '240404012', '240404017', '240405026', '240406011', '240406013', '240406023', '240406001', '240406005', '240406006', '240406008', '240406009', '240406017', '240407015', '240407021', '240407022', '240407029', '240407012', '240407014', '240407018', '240407024', '240407028', '240408023', '240408006', '240408017', '240409003', '240409011', '240409020', '240409004', '240409009', '240409010', '240409013', '240409014', '240409021', '240409024', '240409008', '240410025', '240410001', '240410007', '240410019', '240410026', '240410027', '240410005', '240410015', '240411023', '240411017', '240411028', '240411009', '240411021', '240411012', '240412002', '240412003', '240412005', '240412007', '240412016', '240412022', '240412025', '240412001', '240412004', '240412008', '240412020', '240413021', '240413006', '240413013', '240413028', '240414002', '240414011', '240414015', '240414019', '240414022', '240414026', '240414027', '240414029', '240414009', '240414012', '240414014', '240414018', '240414024', '240414010']\n"
     ]
    }
   ],
   "source": [
    "print games_2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
